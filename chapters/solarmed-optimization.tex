\setchapterpreamble[u]{\margintoc}
\chapter{Towards the optimal coupling and operation of a solar driven \gls{medLabel} system}
\labch{solarmed:optimization}

\tldrbox{ This chapter describes a novel method to develop an operational
    strategy that enables the seamless integration of a solar-driven
    \gls{medLabel} system in an autonomous and optimal manner. The strategy
    includes decisions on when to start or stop each subsystem and how to
    regulate them throughout operation.
    
    The method is based on a hierarchical control approach consisting of three
    layers, where the upper operation layer solves a \gls{minlpLabel} economic
    problem. \\ 
    
    Results from a week-long system simulation are compared against two
    alternative strategies: a baseline heuristic rule-based operation and an
    operation-only optimization (solving a \gls{nlpLabel} problem). The results
    show that the proposed method can significantly improve system performance
    by 32~\% and 21~\%, respectively. This improvement is achieved by fully
    exploiting the flexibility offered by the thermal storage and the solar
    resource, maximizing temperature differences in a manner akin to a
    waste-heat-optimized process. }

%===================================
%===================================
\section{Introduction}

% Estado del arte de la optimización de procesos de desalación térmica
Most of the literature on automatic control of \gls{medLabel} processes focuses
on low-level control strategies. These are typically based on simple control
loops, using either \gls{pidLabel} controllers~\sidecite{roca_solar_2008a} or
\gls{mpcLabel}~\sidecite{gonzalez_economic_2014a}, with the main objective of
maintaining desired temperature setpoints ---primarily the heat source inlet
temperature. A number of works have also addressed optimization of the
\gls{medLabel} process in isolation. For example, Carballo et
al.~\sidecite{carballo_optimal_2018} optimized the steady-state \gls{medLabel}
process using genetic algorithms under different criteria (\eg, maximum
production, highest performance ratio, minimum energy consumption, best
second-law efficiency, and combinations thereof). However, their approach
treated the inlet cooling/seawater flow as a decision variable, which is an
uncontrolled input and therefore may not be applicable in a real-world
scenario. The condenser outlet temperature, which can be regulated through the
cooling water flow, would have been the appropriate decision variable. Chorak et
al.~\sidecite{chorak_experimental_2017} experimentally characterized the pilot
plant described in \refch{solarmed:facility} under a wide range of operating
conditions. Their results highlighted how distillate production and thermal
performance are highly sensitive to the chosen operating point: feedwater flow
rate, condenser operating temperature, and heat source temperature have strong
impacts, whereas the system is less sensitive to variations in heat source flow
rate, owing to its sensible heat transfer nature.

There are inherent limitations in optimizing the \gls{medLabel} process in
isolation, without considering the complete system. As explained in
\refch{solarmed:std}, an \gls{medLabel} plant (or any thermal separator)
requires two forms of energy: heat and electricity. Electricity costs can be
directly assigned using, for instance, market prices. For fossil-fuel-based
thermal energy, it is straightforward to relate operating conditions to fuel
consumption and thus cost. However, when thermal energy is provided by a
variable source such as solar and/or waste heat, the situation becomes more
complex. In the case of solar, its availability is intermittent, and both the
operation and efficiency of the solar field depend strongly on how the
\gls{medLabel} load is managed. The two subsystems are intrinsically coupled.
This complexity is further amplified by the presence of thermal storage, which
enables time-shifting of solar energy use and adds another layer of operational
decisions.

In short, the true cost of thermal energy in a solar-driven system is difficult
to assess, and achieving optimal \gls{medLabel} operation requires optimizing
the entire coupled system.

Several studies have addressed this broader problem at varying levels of
complexity. Roca~\etal~\sidecite{roca_hybrid_2009} developed a hierarchical
hybrid control strategy for the AQUASOL solar desalination plant, when it was a
hybrid \gls{medLabel} system powered by both solar thermal energy and a
gas-fired absorption heat pump. Their approach explicitly models the discrete
operating modes of the facility (solar, solar--recirculation, mixed, and
fossil-fuel), combining a supervisory hybrid predictive controller with local
controllers for the solar field, \gls{medLabel} inlet temperature, and
absorption heat pump. Mode selection is handled through optimization of a hybrid
model that incorporates both continuous dynamics (temperatures, flows) and
logical variables associated with system configuration. While this work
represents one of the earliest attempts to systematically manage operating-mode
switching in solar-driven desalination, the optimization objective is set to
maintain a nominal constant distillate production; it does not consider
electrical-use-associated costs and only considers active operation (no
startup/shutdown of the \gls{medLabel} process)\sidenote{At the time the
facility included a very small thermal storage system, so it would not really
provide much flexibility to take advantage of.}. As a result, the approach
provides robust mode coordination but does not achieve full system-level
optimality. In the same facility, González~\etal~\cite{gonzalez_economic_2014a}
proposed a receding-horizon optimal control strategy with economic objectives
---maximizing water production while minimizing electricity costs. Their work
relied on a simplified linear model, optimizing only the solar field flow while
keeping the \gls{medLabel} inlet temperature constant. 

The most advanced optimization efforts reported in the literature have focused
not on \gls{medLabel}, but on \gls{mdLabel}. In
Porrazzo~\etal~\sidecite{porrazzo_neural_2013}, the authors developed a neural
network-based optimizing control system for a solar-powered seawater
\gls{mdLabel} unit. Because solar energy is intermittent and variable, efficient
operation requires advanced control strategies. A neural network model, trained
on experimental data, was used to capture the relationships between solar
radiation, feed flow rate, inlet water temperature, and distillate production.
This model was then applied to identify optimal feed flow conditions that
maximize distillate output under varying conditions. The proposed control
strategy was validated through simulations and tested in a pilot plant,
demonstrating improved efficiency.

Gil~\etal~\sidecite{gil_hybrid_2019} extended this approach by recognizing that
a solar \gls{mdLabel} plant does not operate as a single continuous process but
transitions through distinct operating modes (\eg, heating the solar field,
charging the storage tank, or running the \gls{mdLabel} module) dictated by
solar and thermal conditions. In their formulation, the switching logic is
predefined: the solar field is started once irradiance exceeds a threshold, the
tank is then charged, and the \gls{mdLabel} module only begins operation once
its inlet temperature reaches a set value. In other words, the decision of when
to start each subsystem is hardwired into the control rules. As a result, these
operating modes are treated as part of the environment, not as free decision
variables ---representing a limitation of the work. To manage the predefined
mode transitions, the authors modeled the facility as a hybrid system and
developed a Hybrid Practial-Nonlinear Model Predictive Control (HPNMPC) scheme.
This framework optimizes flow rates while anticipating and coordinating the
fixed transitions between modes. In doing so, it generalizes the earlier
feedforward optimization into a predictive control framework that incorporates
environmental constraints, enabling more robust operation. Simulation results
showed that the HPNMPC increased operating hours and slightly improved water
production compared to rule-based control. Nevertheless, the choice of
optimization parameters ---operation time, operating temperature, and distillate
production--- together with the omission of electrical consumption, led to
potentially inefficient outcomes. For instance, the system achieved an 11.31~\%
increase in operating time for only a 1.23~\% gain in production, likely at the
expense of higher auxiliary energy consumption.

From this analysis, it can be seen that existing literature on the optimization
of \gls{medLabel} / thermal desalination plants presents significant
limitations. Firstly, many studies on the optimization of \gls{medLabel} plants
either consider too few variables, rely on uncontrollable variables, or use
overly simplified models. From the process analysis in \refch{solarmed:std}, it
was concluded that the key controllable variables that fully define the
operating conditions of an \gls{medLabel} plant are: the heat source flow rate
($q_{med,s}$), the heat source inlet temperature ($T_{med,s,in}$), the feedwater
flow rate ($q_{med,f}$), and the condenser outlet temperature ($T_{med,c,out}$).
These should therefore serve as the decision variables when optimizing plant
operation. 

Secondly, the objective in optimizing desalination processes is to maximize
distillate production while minimizing the resources required. In solar-driven
processes, the solar resource itself has no direct cost. However, its use
requires electricity to recirculate the working fluid through the solar field.
Since the solar field essentially acts as a solar-to-heat converter, the only
relevant consumption to be minimized in the optimization is the electricity
demand of all system components.

A further consideration, often overlooked in the literature, concerns decisions
on when to start and stop the operation of different subsystems in the presence
of thermal storage. Thermal storage allows heat to be used independently of
solar availability ---with certain limits. Depending on its size, this makes the
timing of subsystem operation ---heat generation and thermal load\sidenote{\ie
solar field and \gls{medLabel} plant, respectively}--- crucial for maximizing system
performance both on the current day and over subsequent days. Relying on a fixed
irradiance threshold to trigger the system startup sequence is therefore
suboptimal, as it ignores the state of thermal storage and forecasts of solar
availability that could enable longer or shorter operation of the heat source,
or earlier or later startup and shutdown of the thermal load.

% Contribución
In this work, the operation of a solar-driven \gls{medLabel} system is optimized
with these aspects in mind. This is the first study to include explicit
decisions on when to start and stop each subsystem, while also accounting for a
two-day prediction horizon. This allows the optimization to consider not only
immediate performance, but also the impact of present decisions on future
production. The method relies on an experimentally validated system model that
incorporates the electrical consumption of each component, combined with the
most comprehensive data-driven \gls{medLabel} model currently available in the
literature\sidenote{Described in \nrefch{solarmed:modelling}}.

% Estructura del capítulo
This chapter is structured as follows: first, the optimization problem is
described in \refsec{solarmed:optimization:problem-description}, then the
proposed optimization strategy to solve it is presented in
\refsec{solarmed:optimization:strategy}. The strategy consists on two
fundamental blocks which are detailed in
\nrefsec{solarmed:optimization:op-plan-layer} and
\nrefsec{solarmed:optimization:op-optim-layer}. Finally, the results of the
proposed strategy are presented and compared in detail against alternative
strategies in \refsec{solarmed:optimization:results}.

%===================================
%===================================
\section{Problem description}
\labsec{solarmed:optimization:problem-description}

The behavior of the \gls{solarmedLabel} process is controlled by acting on two
components, a discrete (operation state) and a continuous one (process variables).

The goal is to design an operational strategy that enables the seamless
integration of both subsystems in an autonomous and optimal manner, including
decisions on when to start or stop each subsystem and how to regulate them
during operation. Therefore, considering the whole system as a
\fullgls{minlpLabel} optimization problem\sidenote{See
\nrefsec{intro:optimization:minlp_problems}} that aims to maximize the water
production while minimizing the (electrical) consumption of the system.
Decisions on when to operate the system are weighted considering an optimization
horizon, approximating the operation strategy of the system to the optimum. The
problem is defined in \refprob{solarmed}:

\marginnote[*3]{In general $q$ represents flow rates while $T$ is used for
temperatures. \reffig{solarmed:process-diagram} can be consulted for subscript
reference.}

\marginnote[*8]{$\forall i = 1 \ldots n_{steps}$ is a notation to indicate that
    a condition must be held at every step $i$ in the optimization horizon
    ($n_{steps}$).\\ Bold variables represent vectors.}

\begin{problemcounter}{\gls{solarmedLabel}}
    \begin{equation*}
        \min_{\mathbf{x},\, \mathbf{e};\, \boldsymbol{\theta}} \quad J = f(\mathbf{x}, \mathbf{e}; \boldsymbol{\theta}) = \sum_{i=1}^{n_{steps}} \left( J_{e,i}-J_{w,i} \right)
    \end{equation*}
    
    \textbf{with}:
    \begin{align*}
        \quad for\: i &= 1 \ldots n_{steps}: \\
        & \quad J_{w,i}=q_{d,i} \cdot P_{w,i}\:\text{if } valid\:operation \text{ else 0} \\
        & \quad J_{e,i} = C_{e,i} \cdot P_{e,i} \\
        & \quad q_{d,i},\,C_{e,i},\,valid\:operation=\text{solarmed model}(\mathbf{x}_i, \mathbf{e}_i; \boldsymbol{\theta})
    \end{align*}
    \begin{itemize}
        \item Decision variables
        \[
        \mathbf{x} = [\mathbf{med_{mode}},\,\mathbf{sfts_{mode}},\,\mathbf{q_{sf}},\,\mathbf{q_{ts,src}},\,\mathbf{q_{med,s}},\,\mathbf{q_{med,f}},\,\mathbf{T_{med,s,in}},\,\mathbf{T_{med,c,out}}]
        \]
        where $\mathbf{x}_{nx \times \sum{n_{updates,xi}}}=[x_{1,i},\allowbreak\;
        \ldots,x_{1,n_{updates,x_{1}}},\allowbreak\; \ldots,x_{n_x, n_{updates,
        x_{nx}}}]$
        % where $\mathbf{x}=[x_{1,1},\,\ldots\, x_{1,n_{steps}},\, \ldots,\,
        % x_{n_{x},n_{steps}}]$
        
        \item Environment variables
        \[
        \mathbf{e} = [\mathbf{I},\,\mathbf{T_{amb}},\,\mathbf{T_{med,c,in}},\, \mathbf{P_e},\, \mathbf{P_{w}}]
        \]
        where $\mathbf{e}=[e_{1,1},\,\ldots\, e_{1,n_{steps}},\, \ldots,\,
        e_{n_{e},n_{steps}}]$
    
    \end{itemize}
    
    \textbf{subject to}:
    \begin{itemize}
        
        \item Box-bounds
        \begin{itemize}
            \item $\mathbf{med_{mode}} \in [0,1] \subset \mathbb{Z}$
            \item $\mathbf{sfts_{mode}} \in [0,1] \subset \mathbb{Z}$
            \item $\mathbf{q_{sf}} \in [\underline{q_{sf}}, \overline{q_{sf}}] \subset \mathbb{R}$
            \item $\mathbf{q_{ts,src}} \in [\underline{q_{ts,src}}, \overline{q_{ts,src}}] \subset \mathbb{R}$
            \item $\mathbf{q_{med,s}} \in [\underline{q_{med,s}}, \overline{q_{med,s}}] \subset \mathbb{R}$
            \item $\mathbf{q_{med,f}} \in [\underline{q_{med,f}}, \overline{q_{med,f}}] \subset \mathbb{R}$
            \item $\mathbf{T_{med,s,in}} \in [\underline{T_{med,s,in}}, \overline{T_{med,s,in}}] \subset \mathbb{R}$
            \item $\mathbf{T_{med,c,out}} \in [\underline{T_{med,c,out}}, \overline{T_{med,c,out}}] \subset \mathbb{R}$
        \end{itemize}
    \end{itemize}
    
    \textit{valid operation} conditions, $\forall i = 1 \ldots n_{steps}$:
    \begin{itemize}
        \item $T_{sf,out} \le \overline{T_{sf,out}}$
    \end{itemize}

    \labprob{solarmed}
\end{problemcounter}

% \problemdefinitionbox{\gls{solarmedLabel}}{
% }

\begin{margintable}[*-15]
    \caption[Continuos decision variables box-bounds]{Continuos decision
variables box-bounds. $q_{med,c}$ is not a decision variable but included here
for reference. Its value is determined by a low-level control loop}
    \labtab{solarmed:optimization:box-bounds}
    \resizebox{\linewidth}{!}{%
    \begin{tabular}{rccl}
    \toprule
    \textbf{Variable} & $\mathbf{\underline{x}}$ & $\mathbf{\overline{x}}$ & \textbf{Unit} \\
    \midrule
    $q_{sf}$      & 0.37 & 8.9 & m$^3$/h \\
    $q_{ts,src}$      & 0.9 & 20 & m$^3$/h \\
    $q_{med,s}$      & 30 & 48 & m$^3$/h \\
    $q_{med,f}$      & 5  & 9  & m$^3$/h \\
    $q_{med,c}$      & 3  & 22  & m$^3$/h \\
    $T_{med,s,in}$   & 55 & 81 & $^\circ$C \\
    $T_{med,c,out}$ &
    \begin{tabular}{@{}c@{}} $T_{med,c,in}$ \\ +1.5 \end{tabular} &
    \begin{tabular}{@{}c@{}} $T_{med,c,in}$ \\ +25 \end{tabular} &
    $^\circ$C \\
    \bottomrule
    \end{tabular}
    }
\end{margintable}


Where the objective is to minimize the cumulative cost of operation ($J$).
Fresh water ($q_{med,d}$) sold ($J_w$) at price $P_w$ is the negative term
while electrical consumptions ($C_e$) at price $P_e$ make up the positive cost
term ($J_e$). The benefit ($B$) of operation is simply the negative of the cost
of operation, $B=-J$.

The environment is represented by the vector $\mathbf{e}$, which includes the
global solar irradiance ($\mathbf{I}$), ambient temperature
($\mathbf{T_{amb}}$), and the prices of water ($\mathbf{P_w}$) and electricity
($\mathbf{P_e}$).

The decision vector $\mathbf{x}$ is composed of the decision variables for both
the discrete and the continuous space. Two decision variables are defined to
manipulate the discrete state of each subsystem defined in
\refsec{solarmed:modelling:discrete}: $med_{mode}$ and
$sfts_{mode}$. These binary ($\subset \mathbb{Z}$) variables
establish whether the particular subsystem is active ($x_i=1$) or inactive
($x_i=0$). This is directly related to the operation state of the particular
subsystem\sidenote{As defined in
Tables~\ref{tab:solarmed:modelling:sfts_fsm_states} and
\ref{tab:solarmed:modelling:med_fsm_states}.\\
Once the values for these decision variables are provided, the low-level control
layer is in charge of safely transitioning between operation states \eg:\\[1ex]
· $med_{mode}: 0 \rightarrow 1$ \\
· med state: \textit{off} $\rightarrow$ \textit{generating vacuum} $\rightarrow$ \textit{starting-up} $\rightarrow$\textit{active}\\
} and accounted for in the models by the integrated finite-state
machines as explained in \refsec{solarmed:modelling:discrete}. For the
continuous space, the decision variables include the ones that define the
operating conditions (\ie operation point) of the \gls{medLabel} system, and the
two recirculation flow rates that determine the conditions of the heat source
($q_{sf}$, $q_{ts,src}$).

The decision vector ($\mathbf{x}$) is constructed by repeating each decision
variable ($x_i$) as many times as the number of updates defined for it
($n_{updates, x_i}$)\sidenote{The reason for this parameter is explained in the
following section}:
\begin{equation}
    \mathbf{x}_{n_x \times \sum n_{updates, x_i}} = 
    [x_{1,1}, \ldots, x_{1, n_{updates, x_1}}, 
    \ldots, x_{n_x, n_{updates, x_{n_x}}}]
    \labeq{solarmed:optimization:decision_vector}
\end{equation}


%================================
%================================
\subsection{Implementation discussion}
\labsec{solarmed:optimization:implementation}

%==============================
\subsubsection{On the constraint handling}
\labsec{solarmed:optimization:constraints-discussion}

No constraints are explicitly defined in the problem definition. This is because
the constraints are implicitly defined in the model equations, which are used to
evaluate the objective function. This design decision is motivated to avoid the
need for a constraint-handling capable optimization algorithm, limiting the
choice for an already complex \gls{minlpLabel} problem\sidenote{See
\nrefsec{intro:optimization:constraints} for a more detailed discussion on the
topic}. Specifically, two aspects demand further consideration:

\begin{enumerate}
    \item The decision value for the \gls{medLabel} outlet condenser temperature
    ($T_{med,c,out}$) is not a direct input to the system, but rather a setpoint
    to be followed by a low-level control loop by manipulating the cooling water
    flow rate ($q_{med,c}$). This input might saturate and thus not be able to
    achieve the desired setpoint\sidenote{Value initially intended by the
    optimization}. In this case, a new validated value for the decision variable
    is computed, which is the minimum (or maximum) value that can be achieved by
    saturating the cooling water flow rate ---with $\overline{q_{med,c}}$ or
    $\underline{q_{med,c}}$, respectively. 
    
    In this case, the value used in the \gls{solarmedLabel} and the output from
    the optimization to the low-level control layer would be the validated value
    for $T_{med,c,out}$. No additional actions are needed.

    \item In the solar field, in order to not constantly interrupt the
    evaluation due to the solar field temperature going above
    $\overline{T_{sf,out}}$ (120 $^\circ$C), the model saturates this
    temperature when going above and sets a flag. The limitation of this
    approach is that when there is low energy demand from the load, and likely
    because it favors energy transfer in the heat exchanger\sidenote{greater
    temperature difference in primary side instead of greater mass flow rate
    with its associated increase in pumping power}, it has been observed that
    the optimizer tends to minimize the solar field flow, and systematically
    lets the solar field outlet temperature reach the limit. To avoid this
    situation, the positive term of the objective function is nullified in
    iterations where the constraint is not met.
    
    Here, in order to ensure \textit{valid operation} the fitness function is
    manipulated to de-incentivize decision variable values that lead to
    unfeasible operation. 

\end{enumerate}

\subsubsection{On the prediction horizon}
\labsec{solarmed:optimization:decision_variables-discussion}

The problem is designed as an optimization problem with a shrinking
horizon\marginreminder[*-2]{Shrinking horizon optimization}{ An optimization
where the horizon end is fixed, and as time progresses, the start of the horizon
moves forward.\footnote{See \nrefsec{intro:optimization}} }. The horizon size
should be large enough so that decisions on how to operate the system are made
with perspective, taking into account how they will affect the system in the
future, but not so large that current decisions have no impact on the far
future, and make the problem dimensionality unmanageable. 

For this case study, this parameter should be chosen based on the hours of
capacity of the thermal storage to operate the \gls{medLabel} system.

The thermal storage capacity allows the system to operate with no supply from
the solar field for several hours. This means that depending on the charge state
of the thermal storage, the system could start operation independently of the
irradiance conditions, or operate at different levels of temperature.
Considering this the optimization horizon chosen was 36 hours. This means that
if the optimization horizon starts early on day~1 at 6:00, the fitness function
is evaluated until 18:00 of day 2 \ie including the end of operation on the
second day.

%===================================
%===================================
\subsubsection{On solving the optimization problem}
\labsec{solarmed:optimization:solving-discussion}

Solving the optimization problem for this \fullgls{minlpLabel} formulation
presents significant challenges due to the combinatorial nature of the integer
decision variables~\sidecite{grossmann_advanced_2021}. As shown in
\reffig{solarmed:optimization:decision_tree}, each combination of integer
decisions, such as the operational modes of the separation subsystem
($med_{mode}$) and the solar field thermal storage subsystem ($sfts_{mode}$),
leads to a different system trajectory along the prediction
horizon\sidenote{This will be referred to as: \textbf{operation plan}}.

The number of possible operation trajectories increases exponentially with both
the number of integer variables ($n_{xi}$) and the number of decision updates
($n_{\text{updates}, xi}$), following the expression:

\begin{equation}
    \labeq{solarmed:optimization:n_problems}
    n_{\text{problems}} = n_{xi}^{n_{\text{updates}, xi}}.
\end{equation}

This exponential growth makes the search space extremely large and
complex\sidenote[][*-3]{For example (with $n_{xi}=2$): \\
$n_{\text{updates}, \forall xi}=6 \rightarrow n_{problems} = 64$, \\
$n_{\text{updates}, \forall xi}=24 \rightarrow n_{problems} = 16\,777\,216$}.

An important design consideration when solving the optimization problem is
whether the sequence of integer decisions (\ie, operational mode transitions
over time) is predefined or whether the optimization algorithm is allowed to
explore the decision tree freely and determine the optimal sequence. The latter
case requires more computational effort but allows for potentially better-performing
solutions.

\subsubsection{On the (continuous) decision variables update frequency}
\labsec{solarmed:optimization:decision_variables-discussion}

Apart from the integer decision variables combinatory nature, using a uniform
update frequency for all continuous variables can cause the decision vector to
grow rapidly over long horizons, often with diminishing returns. To avoid this,
each continuous decision variable is assigned a number of updates, \(
n_{\text{updates}, x_i} \in [1, n_{\text{steps}}] \).

This tunnable parameter can be chosen independently for each decision variable,
where variables associated with faster dynamics (\eg, \( q_{sf} \), \(
q_{ts,src} \)) receive more frequent updates. These updates are distributed
evenly across the \emph{active} period of the corresponding subsystem within the
horizon. This prevents updates from being wasted during inactive intervals
(\eg, the gap between the end of operation on day~1 and the start on day~2).

\begin{marginfigure}[-9.5cm]
    \includegraphics[]{solarmed-optimization-decision_tree.png}
    \caption{Decision tree resulting from the combinatorial nature of the integer part of the optimization problem. Text in nodes represents system states.}
    \labfig{solarmed:optimization:decision_tree}
\end{marginfigure}

This approach also implies that the continuous variables of the decision vector
can only be defined after the integer component is established, since the latter
determines the subsystem active periods. 

% Once timestamps are assigned to each
% decision variable, their values are resampled to match the desired temporal
% resolution of the optimization problem. This resampling is performed by
% forward-filling the latest known value until the next update
% time~\cite{hyndman_forecasting_2021}.

%===================================
\section[]{Proposed optimization strategy}[Proposed strategy]
\labsec{solarmed:optimization:strategy}

A hierarchical control approach (see
\reffig{solarmed:optimization:architecture}) was chosen consisting of three
layers: operation plan, operation optimization, and control. This scheme was
chosen for two main reasons. On the one hand, the time scales of the different
aspects of the operation of the system (operation mode changes, process
variables setpoint changes, regulatory control, respectively) can differ
substantially. Secondly, it allows to abstract process complexity from the more
computationally demanding upper layers by allocating it into the downstream
layers. The operation plan layer makes decisions for the \textit{operation
modes}, the operation optimization layer sets the setpoints given to the
continuous \textit{process variables} that are to be followed by the low-level
regulatory control layer.

\begin{marginfigure}[-1cm]
    \includegraphics[]{solarmed-optimization-architecture.png}
    \caption{Proposed optimization strategy architecture}
    \labfig{solarmed:optimization:architecture}
\end{marginfigure}

Both operation plan and operation optimization layers share the same underlying
problem structure, the difference being that the operation plan layer evaluates
a predefined library of $\text{n}_{\text{problems}}$ combinations of the binary
decision variables $med_{mode}$ and $sfts_{mode}$ twice; once to
decide the operation start, and another to end operation. The operation
optimization layer periodically solves a single \gls{nlpLabel} problem with the
selected values for these two variables fixed. They are further described in
the following sections.

% This layered optimization procedure is illustrated in
% \reffig{solarmed:optimization:architecture} where it can be seen that the
% proposed strategy is composed by an ordered sequence of evaluations of the
% different layers. 

\section{Operation plan layer description}
\labsec{solarmed:optimization:op-plan-layer}

\marginnote[*9]{The number of updates available for each integer variable
$n_{updates,xi}$ will be interchangeably referred to as \fullgls{dofLabel}.}

This layer determines the integer decision variables of the \gls{minlpLabel}
problem, namely, the sequence of operation modes producing an operation plan. To
make the problem computationally tractable, only a limited number of
combinations, $n_{problems}$, are evaluated. This transforms the mixed-integer
problem into a simpler form by moving the integer variables from the decision to
the environment space. In effect, the original \textbf{\gls{minlpLabel}} is
decomposed into a library of \textbf{\gls{nlpLabel}}
problems\sidenote[][*5]{\textbf{\gls{minlpLabel}}~$\rightarrow$~\textbf{n\gls{nlpLabel}}}
that are individually evaluated, \gls{nnlpLabel}.

% As mentioned, two evaluations of this layer are performed at different times:
% one to plan subsystem start-up, and another to schedule shutdown.  

To improve robustness, the layer can be evaluated multiple times ($n_{evals}$)
under different scenarios ---typically reflecting variations in forecasted
environmental conditions. The final operation plan is selected as the best
compromise across these scenarios using a composite evaluation metric.

This composite score considers three aspects in the performance across different
scenarios. Each alternative is assessed according to: its average performance,
its consistency across scenarios, and its robustness in the worst-case
situation. The average performance \( \mu_i \) reflects the overall expected
behavior of the alternative, while the standard deviation \( \sigma_i \)
captures its sensitivity to scenario variability, penalizing options that
exhibit large fluctuations in performance. Similarly, the worst-case performance
\( W_i \) represents the most adverse outcome among all considered scenarios,
ensuring that alternatives prone to extreme negative results are appropriately
penalized. These three components are combined into a single composite score
($S_i$), where weighting factors control the influence of consistency and
worst-case penalties relative to the mean performance. The alternative with the
lowest composite score is selected as the most balanced and robust solution
according to \refeq{solarmed:optimization:composite_score}.

\begin{equation}
    \labeq{solarmed:optimization:composite_score}
S_i = \mu_i + w_{\mathrm{std}} \, \sigma_i + w_{\mathrm{wc}} \, W_i,
\end{equation}

\noindent where \( w_{\mathrm{std}} \) is the weight applied to the standard
deviation penalty and \( w_{\mathrm{wc}} \) is the weight applied to the worst-case
penalty.


The time required to perform this layer's computation is denoted
$\Delta t_{eval,plan}$.

\subsection{Candidate problems generation}

Given the available computational resources and the complexity of the objective
function, it has been found feasible to evaluate in the order of $n_{problems}
\sim 100$ candidate combinations. This constraint informs how many
\gls{dofLabel} (\ie number of updates available for the operation modes) can be
defined by using \refeq{solarmed:optimization:n_problems}. The particular design
choice for the number of updates per subsystem is shown in
\reftab{solarmed:optimization:dof}. In total, 101 distinct operation plans are
generated for the start-up evaluation and 144 for the
shutdown\sidenote[][*-2]{Notice the total number does not match exactly
\refeq{solarmed:optimization:n_problems} since special cases are added like
keeping subsystems inactive for the whole day}.

\begin{table}[htbp]
\centering
\caption[Operation plan layer. Degrees of freedom assignment.]{Operation plan layer. Degrees of freedom assignment for changes in the operation state for start-up (1) and shutdown (2) evaluations.}
\labtab{solarmed:optimization:dof}
\resizebox{\textwidth}{!}{%
\begin{tabular}{rrrccccccclc}
\cline{2-12}
 & \multicolumn{1}{c}{\multirow{3}{*}{\textbf{Subsystem}}} &  & \multicolumn{7}{l}{\textbf{Degrees of freedom}} &  & \multirow{3}{*}{$\textbf{n}_{\textbf{problems}}$} \\ \cline{4-10}
 & \multicolumn{1}{c}{} &  & \multicolumn{3}{l}{Day~1} &  & \multicolumn{3}{l}{Day 2} &  &  \\ \cline{4-6} \cline{8-10}
 & \multicolumn{1}{c}{} &  & Start &  & Stop &  & Start &  & Stop &  &  \\ \cline{2-2} \cline{4-4} \cline{6-6} \cline{8-8} \cline{10-10} \cline{12-12} 
\multirow{2}{*}{Evaluation: Start-up (1)} & sfts &  & 3 &  & 3 &  & 1 &  & 1 &  & \multirow{2}{*}{101} \\
 & med &  & 3 &  & 3 &  & 1 &  & 1 &  &  \\ \cline{2-12} 
\multirow{2}{*}{Evaluation: Shutdown (2)} & sfts &  & - &  & 3 &  & 2 &  & 2 &  & \multirow{2}{*}{144} \\
 & med &  & - &  & 3 &  & 2 &  & 2 &  &  \\ \cline{2-12} 
\end{tabular}%
}
\end{table}

In \reftab{solarmed:optimization:dof}, it can be seen that the available
\gls{dofLabel} are assigned asymmetrically between the two days of the
prediction horizon. More \gls{dofLabel} (\ie flexibility) are given to the
actions closer in time to the evaluation. For example, the start and stop
actions in day~1 for the start-up evaluation (1) have a more direct impact on
the immediate operation of the system. Conversely, fewer \gls{dofLabel} are
allocated to day 2 actions, as these decisions are more speculative and have a
less direct effect on the current operation. For the shutdown evaluation (2), no
start actions are considered in day~1 since the system is already operational,
and day 2 operation becomes more relevant when deciding when to stop operation
in day~1, hence the allocation of more \gls{dofLabel} to day 2
actions.
% \sidenote{\gls{dofLabel}=2 for start and stop in day 2}.

This allocation strategy balances the need for flexibility in near-term
decisions with the computational constraints of evaluating a large number of
operation plans. 

\subsection{Update times generation}

Up to this stage, the operation plans generated consist merely of lists of ones
and zeros for each subsystem, indicating whether the subsystem is active or
inactive at each update. The next step is to assign these operation mode updates
to specific time instants\sidenote[][*-5]{Which can then be resampled to match
the desired sampling time of the optimization problem. As with the continuous
component of the decision vector, this is achieved by forward-filling the values
until the next update time. This approach is also known as \textit{Last
Observation Carried Forward}~\cite{hyndman_forecasting_2021}}.

To maintain solutions close to the optimal one while keeping the problem
computationally tractable, the limited updates are distributed along the
prediction horizon at strategic time instants. Since the case study system is
fundamentally solar-driven, its operation is highly dependent on irradiance
availability, and thus changes in operation typically occur at the beginning and
end of the solar day. 

\begin{marginfigure}[-1.5cm]
    \includegraphics[]{figures/solarmed-optimization-updates_distribution.png}
    \caption{Operation mode updates time distribution. The thick-yellow line illustrates the irradiance.}
    \labfig{solarmed:optimization:updates_distribution}
\end{marginfigure}

The temporal distribution of operation mode updates is shown in
\reffig{solarmed:optimization:updates_distribution}, which depends on the number
of available updates (\gls{dofLabel}). These update times are determined based
on the solar irradiance profile and are bounded by lower and upper
thresholds\sidenote[][*5]{Being these two values two tunnable parameters of the
method}. Depending on the type of operation (start-up or shutdown), these
thresholds are referred to as early/late start or early/late stop thresholds,
respectively.

In \reffig{solarmed:optimization:updates_distribution}, up to three
\gls{dofLabel} are illustrated. If only one update (1~\gls{dofLabel}) is
available (1~\gls{dofLabel}), it is placed at the midpoint between the early and
late thresholds. When two \gls{dofLabel} are available, they are located at the
early threshold and the midpoint, and at the late threshold, respectively. With
three \gls{dofLabel}, the subsystem updates occur at the early, average, and
late thresholds. For the \gls{medLabel} subsystem, these updates can  be delayed
with respect to those of the \gls{sftsLabel} subsystem as illustrated in
\reffig{solarmed:optimization:updates_distribution} -- 2~\gls{dofLabel}. If more
\gls{dofLabel} are available, additional thresholds can be introduced as needed. 

The relative shift or delay between subsystems acts as an additional tuning
parameter of the methodology. However, for simplicity, this offset has been set
to zero, as the inherent differences in subsystem start-up times already provide
a natural temporal offset. Combined with the varying number of
\gls{dofLabel} assigned to each subsystem, this configuration naturally results
in staggered operation changes across the candidate problems.




% \begin{figure*}
%     \centering
%     \subfloat[\centering Computation timeline]{{\includegraphics[width=0.48\linewidth]{solarmed-optimization-timeline.png}}}%
%     \hspace{0.01\linewidth}
%     \subfloat[\centering Operation mode updates time distribution]{{\includegraphics[width=0.48\linewidth]{solarmed-optimization-updates_distribution.png}}}%
%     \caption[Operation plan layer computation and updates distribution]{Operation plan layer computation and updates distribution. The yellow line represents the irradiance illustrating the solar day.}%
%     \labfig{solarmed:optimization:operation_plan:method}
% \end{figure*}


Given a number of updates per subsystem and the update times assigned, the
potential operation time change candidates are defined as:

\[
    t_{mode-change,candidates} =  \left[t_0,\, t_1,\, \ldots,\, t_{\max(n_{updates,\forall x_i})}\right]
\]

They are ordered in ascending order, where $t_0$ is the earliest potential operation
change time and $t_{\max(n_{updates,\forall x_i})}$ is the latest potential
operation change time\sidenote[][*-3]{Based on this definition, the earliest potential
subsystem start-up would be at $t_{\uparrow, candidates}(0)$. Similarly, the
earliest potential shutdown would be at $t_{\downarrow, candidates}(0)$.}.



\subsubsection{Start-up}
\labsec{solarmed:optimization:operation_plan:start-up}

This is the first evaluation of the proposed methodology as illustrated in
\reffig{solarmed:optimization:methodology_timeline}~\texttt{(1)} ---which
represents the computation timeline of the proposed methodology. It is computed
ahead of the first potential operation mode change
($t_{\uparrow,candidates}(0)$)\sidenote[][*-3]{Nomenclature: $\uparrow$
indicates startup, $\downarrow$ indicates shutdown}, with enough lead time to
complete the evaluation before any potential change in operation
mode\sidenote[][*-2]{This is represented by the first yellow triangle group
({\large \trianglemarker[D6B656]{up}}) in
\reffig{solarmed:optimization:methodology_timeline}}:

\[
    t=t_{\uparrow,candidates}(0) - (\Delta t_{eval,plan}\times n_{evals})
\]

The primary goal of this evaluation is to determine the optimal timing for
activating the subsystems\sidenote[][*-3]{Yellow upward-pointing triangles ({\large
\trianglemarker[D6B656]{up}}) in
\reffig{solarmed:optimization:methodology_timeline}~\texttt{(3)}}, while a
secondary objective is to provide an initial estimate for their shutdown
schedule\sidenote[][*-2]{Yellow downward-pointing triangles ({\large
\trianglemarker[D6B656]{down}}) in
\reffig{solarmed:optimization:methodology_timeline}~\texttt{(5)}}.

\begin{figure*}[htbp]
    \includegraphics[]{figures/solarmed_optimization_methodology_timeline.png}
    \caption{Proposed n\gls{nlpLabel} methodology computation timeline.
    \texttt{(1)}~Operation plan start-up evaluation. \texttt{(2)}~Start of
    operation optimization evaluation train. \texttt{(3)}~System operation
    start. \texttt{(4)}~Operation plan shutdown evaluataion and
    \texttt{(5)}~System operation end.}
    \labfig{solarmed:optimization:methodology_timeline}
\end{figure*}

As the earliest evaluation, it considers the longest prediction horizon and
therefore deals with the highest uncertainty in the predicted variables. On the
other hand, starting the evaluation early provides ample computation time---
several hours in advance ---to perform multiple assessments under different
\textit{scenarios}. In this work, three evaluations ($n_{evals}=3$) are
conducted using distinct solar irradiance estimates. Irradiance is selected as
the uncertain variable because it has the strongest influence on system
operation and performance. The three scenarios considered are: a nominal
scenario based on the forecasted environmental conditions, a pessimistic
scenario with a 20~\% decrease in the expected solar irradiance, and an
optimistic scenario with a 20~\% increase in the expected solar irradiance.

\subsubsection{Shutdown}

A second evaluation is carried out later in the day, prior to system shutdown
(see \reffig{solarmed:optimization:methodology_timeline}~\texttt{(4)}). Its
objective is to determine the most appropriate moment to stop operations based
on the most up-to-date system state information\sidenote{Represented in
\reffig{solarmed:optimization:methodology_timeline}~\texttt{(5)} as red
downwards-pointing triangles ({\large \trianglemarker[B85450]{down}})}. This
evaluation also includes \gls{dofLabel} related to the operation schedule of the
following day, enabling the shutdown decision for day~1 to account for its
influence on the start and end times of day~2\sidenote{See
\reftab{solarmed:optimization:dof}}.

Only a single scenario evaluation is required, since the uncertainty in the prediction
horizon at this stage is considerably lower than during the start-up evaluation.
It is executed in parallel with the operation optimization
layer\sidenote{Explained in the following section} and triggered shortly before
the earliest expected shutdown time of any subsystem estimated by the start-up
evaluation, $t_{\downarrow, candidates}(0)$, while accounting for subsystem
shutdown constraints:

\[
    t = t_{\downarrow, candidates}(0) - \Delta t_{eval, plan}
\]

Once the evaluation is completed, the integer decisions are updated in the
immediate posterior operation optimization layer. Faster computation is
advantageous, as it allows the operation optimization layer to re-optimize the
control trajectory for the actual shutdown time and adapt as soon as possible
system operation accordingly.

\subsubsection{Candidate problems evaluation}

\marginannotation[]{Operation plan composite score \vs Candidate problems ranked
evaluation}{
The ranked evaluation introduced here should not be confused with the
composite score defined at the beginning of the section.\\
The operation plan layer may be evaluated multiple times under different
environment scenarios. The composite score is used to select the best
candidate problem across those scenarios. In contrast, the ranked
evaluation increases the computational efficiency of each evaluation by
progressively discarding the worst-performing candidate problems, thereby
reducing the number that must be evolved until the final iteration.
}

The candidate problems are evaluated by evolving each of them individually in a
ranked evaluation. The concept involves keeping a collection of candidate
problems that are evaluated in stages. First, a maximum number of objective
function evaluations per problem and a number of stages is established. With
this information, the number of iterations per stage can be computed. After each
evaluation stage, the problems are ranked based on their performance, and a
fraction of the worst-performing ones are removed from the collection. This
process is repeated over time so that the library gradually focuses on the
better-performing problems while discarding the less successful ones.

This strategy provides a trade-off between exploring a wide range of operation
plans, initially, but gradually concentrating computational resources on the most
promising candidates. If too agressive pruning is applied, there is a risk of
discarding potentially good solutions early on. Conversely, if pruning is too
lenient, computational resources may be wasted on poor-performing candidates.


\section{Operation optimization layer description}
\labsec{solarmed:optimization:op-optim-layer}

As mentioned, this middle layer establishes the setpoints for the continuous
process variables, \ie the continuous part of the \gls{minlpLabel} problem. It
is depicted in \reffig{solarmed:optimization:methodology_timeline} --
\textit{Operation optimization} and its evaluation cycle starts at~\texttt{(2)}.
The operation optimization layer evaluates periodically, with a sample time
$T_{eval,optim}$, a \gls{nlpLabel} problem where the integer decision variables
are fixed to the values provided by the operation plan layer\sidenote{It is
exactly equivalent to the operation plan layer problem, just making
$n_{problems}=1$}. It uses the latest available state of the system and
environment predictions to evaluate the objective function.

The layer computation time is named $\Delta t_{eval,optim}$.

One key feature to increase the computational efficiency of this layer, is to
provide initial solutions for decision variables based on: 

\begin{itemize}
    \item this layer previous solution (if available), or
    \item the best candidate problem solution from the operation plan layer
    evaluation.
\end{itemize}

This warm-starting strategy helps to speed up the convergence of the
optimization algorithm by starting from a solution that is already close to
optimal.

\begin{kaobox}[title=\gls{solarmedLabel} \gls{nnlpLabel} optimization methodology]

    \begin{enumerate}
        \item Generate operation mode change candidates based on the available
        updates per subsystem (\gls{dofLabel}) and irradiance thresholds.
        \item Before the first potential operation change and considering the
        evaluation time, $t=t_{\uparrow,candidates}(0) - (\Delta
        t_{eval,plan}\times n_{evals})$, evaluate the operation plan layer to
        establish the operation start of the subsystems and an estimation of
        when to stop.
        
        \item Before the established startup and considering the layer evaluation time, $t=t_{\uparrow} - \Delta
        t_{eval,optim}$, start evaluating the operation optimization layer
        periodically ($T_{eval,optim}$) to establish the setpoints for the
        continuous process variables.

        \item Before the earliest subsystem projected shutdown and considering
        the operation optimization layer evaluation time,
        $t=t_{\downarrow,candidates}(0) - \Delta t_{eval,plan}$, evaluate
        the operation plan layer, in parallel to the operation optimization layer,
        to establish the shutdown time of the subsystems.

        \item Continue evaluating the operation optimization layer periodically
        ($T_{eval,optim}$) until the last subsystem is shutdown.
    \end{enumerate}

\end{kaobox}


\section{Alternative strategies}
\labsec{solarmed:optimization:heuristic}

\textbf{Heuristic approach}. This alternative makes use of a rule-based approach to decide when to start and
stop the subsystems based on threshold values of the solar irradiance and the
thermal storage state of charge. The rules are defined as follows:

\begin{itemize}
    \item Start solar field operation when the solar irradiance exceeds a
    predefined threshold ($I_{\uparrow}=500$~W/m$^2$). Stop operation when it
    falls below a lower threshold ($I_{\downarrow}=400$~W/m$^2$).
    
    \item Start thermal storage charging when the solar field outlet temperature
    exceeds the one of the (top) hot tank: $T_{sf,out} > T_{ts,h,t}$. Stop
    charging when the solar field outlet temperature falls below the hot tank
    temperature: $T_{sf,out} < T_{ts,h,t}$.
    
    \item Start \gls{medLabel} operation when the thermal storage is above
    76~$^\circ$C. Stop operation when it falls below 65~$^\circ$C.
\end{itemize}

As for the continuous decision variables:

\begin{itemize}
    \item The \gls{medLabel} operates fixed
    setpoints at nominal conditions: $T_{med,s,in}=74$~$^\circ$C,
    $q_{med,f}=8$~m$^3$/h, $q_{med,s}=12$~l/s, $T_{med,c,out}=28$~$^\circ$C. 
    
    \item The solar field recirculation flow rate is set to maintain the solar
    field outlet temperature at 90~$^\circ$C. 
    
    \item The thermal storage recirculation flow rate is set to maximize the
    heat transfer from the solar field while keeping the inlet hot tank
    temperature above its current value to avoid colder water mixing.

    \[
    \begin{aligned}
    &\max_{q_{ts,src};e;\Theta}{\dot{Q}_{ts,src}} \\
    &\text{subject to:} \quad  T_{ts,h,in} > \min\left(T_{ts,h,t},\, 90^\circ\text{C}\right)
    \end{aligned}
    \]
\end{itemize}

\textbf{\gls{nlpLabel} approach}. Similar to the proposed n\gls{nlpLabel}
strategy, this alternative also employs a \gls{nlpLabel} formulation to optimize
the continuous decision variables. However, it differs by fixing the integer
decision variables using the same irradiance-level thresholds.